{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3주차5강_머신러닝_분류_문제[2].ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5sun6tgkUhDpMtaGJIByt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jang262/jang262.github.io/blob/master/3%EC%A3%BC%EC%B0%A85%EA%B0%95_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EB%B6%84%EB%A5%98_%EB%AC%B8%EC%A0%9C%5B2%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoqJyZSQP1Vv",
        "colab_type": "text"
      },
      "source": [
        "과서 몇년전 까지만 해도 뉴스나 신문기사에 등장하는  \n",
        "인공지능은 학습과정을 알수 없는 블랙박스 그 자체였습니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84607696-a8c02880-aee9-11ea-8926-8d9276f003a2.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]1\" alt=\"RubberDuck\"></img><br/>\n",
        "\n",
        "하지만 오늘 첫번째로 살펴볼 모델은  \n",
        "결과로 나온 이후에 대한 설명이 아주 중요할때 사용되는  \n",
        "**결정트리(Decision tree)** 그리고 조금은 특이한 모델인 **k-근접이웃(K-Nearest Neighver)** 입니다.\n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84607765-166c5480-aeea-11ea-90ca-a0843b31b1e3.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]2\" alt=\"RubberDuck\"></img><br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wG_Gly2XdlC",
        "colab_type": "text"
      },
      "source": [
        "# 결정트리(Decision tree)  \n",
        "**결정트리(Decision tree)**는 앞서 이야기한 것 처럼  \n",
        "설명이 중요할때 아주 유용하게 사용되죠.  \n",
        "이름에서 느껴지는것 처럼 일련의 질문에 대한 결정을 통해  \n",
        "데이터를 분해하는 모델입니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84607978-289ac280-aeeb-11ea-98b1-5d848c57a54b.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]3\" alt=\"RubberDuck\"></img><br/>\n",
        "\n",
        "이렇게  어떤일을 할지 선택하기 위한 결정 트리는  \n",
        "<u>훈련데이터에 있는 변수 즉, 특성을 기반으로 새로운 샘플에 클래스 레이블을  \n",
        "추정할 수 있도록 일련의 질문을 학습하게 됩니다.</u>  \n",
        "물론 지금 이 그림은 범주형 변수를 사용한 예를 보여주고 있지만,  \n",
        "동일한 개념으로 실수형 특성에서도 적용된다는 점이 매력적이죠. \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84608178-208f5280-aeec-11ea-8d60-85e114ca898c.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]4\" alt=\"RubberDuck\"></img><br/>\n",
        "이 결정 알고리즘을 사용하면 트리의 루트에서 시작해,  \n",
        "**정보이득(Information Gain, IG)**이란 값이 최대가 되는 특성으로 데이터를 나눕니다.  \n",
        "이러한 결정을 **리프 노드(leat node)**가 순수해질 때 까지 모든 자식 노드에서 이 분할 작업을 반복합니다.  \n",
        "\n",
        "하지만 이와 같은 분할 작업을 계속하다보면 깊은 트리가 만들어지게 되는데,  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84608243-7106b000-aeec-11ea-9721-961aba3a7b7c.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]5\" alt=\"RubberDuck\"></img><br/>\n",
        "이는 곧 **과적합**을 불러일으킬 수 있죠.  \n",
        "\n",
        "그래서 일반적으로 트리의 최대 깊이를 제한하여 **트리를 가지치기(트리 가지치기 : pruning)** 합니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84608317-d8246480-aeec-11ea-8464-b04a8df85ffc.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]6\" alt=\"RubberDuck\"></img><br/>\n",
        "마치 나무의 가지들이 너무 많아지는 것을 막기 위해  \n",
        "정원사가 가지치기를 하는것 처럼 말이죠.  \n",
        "\n",
        "자 그럼 이를 조금 더 자세하게 살펴보겠습니다.  \n",
        "\n",
        "머신러닝 알고리즘의 핵심 과정인 목적함수의 목적부터 살펴보면,  \n",
        "<u>가장 정보가 풍성한 특성으로 노드를 나누기 위함이며,  \n",
        "이를 트리 알고리즘으로 최적화 해줘야 합니다.</u>  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84608432-61d43200-aeed-11ea-95ce-a789edf6682d.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]7\" alt=\"RubberDuck\"></img><br/>\n",
        "그럼 앞서 이야기한 것처럼 이 목적함수는 각 분할에서 정보 이득을 최대화해야 한다는  \n",
        "임무를 가지고 있죠. 이를 수식으로 정의하면 이렇게 되고요.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtapSD7jkfj7",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "또 다시 무슨 의미인지 전혀 알수 없는 무엇인가가 등장 했을때 하나하나 뜯어보는게 제일 좋은것 같습니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84608498-c1324200-aeed-11ea-8715-effafbbb1c9c.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]8\" alt=\"RubberDuck\"></img><br/>\n",
        "여기서 f는 어떠한 분할기법을 사용할 것인지를 나타냅니다.  \n",
        "그리고 Dp와 Dj는 부모와 j번째 자식 노드의 데이터 셋입니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84608537-e921a580-aeed-11ea-94c3-8be25d973fcd.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]9\" alt=\"RubberDuck\"></img><br/>\n",
        "다음 I는 **불순도 지표**를 뜻하며,  \n",
        "Np는 부모노드에 있는 전체 데이터의 개수입니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84608666-6fd68280-aeee-11ea-8f59-2fe3e7cd574d.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]10\" alt=\"RubberDuck\"></img><br/>\n",
        "그럼 Nj도 j번째 자식 노드에 있는 데이터의 개수라는 걸 알 수 있죠.  \n",
        "자 그럼 여기서 알 수 있는 건 정보 이득은, 단순하게 부모 노드의 불순도와  \n",
        "자식 노드의 불순도 합의 차이라는 점입니다.  \n",
        "또 이와 연계해서 자식 노드의 불순도가 낮을 수록 정보 이득은 커지게 된다는 점입니다.  \n",
        "\n",
        "이때 대부분의 라이브러리들은 구현을 간단하게 하고,  \n",
        "탐색 공간을 줄이기 위해 **이진 결정 트리**를 사용합니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84608860-58e46000-aeef-11ea-9796-2fd642dcee73.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]11\" alt=\"RubberDuck\"></img><br/>\n",
        "즉, 부모 노드를 두 개의 자식 노드 D left와 D right로 나눠버린다는 이야기가 되죠.  \n",
        "그리고 수식을 이렇게 다시 재정의 할 수 있습니다.  \n",
        "그럼 **이진 분류**를 하기 위해서는 어떠한 분할 조건 혹은 불순도 지표를  \n",
        "사용해야 한다는 이야기가 되는데, 이때 널리 사용되는 <u>세가지 불순도 지표  \n",
        "혹은 분할 조건 중</u>  \n",
        "첫번째, **지니 불순도**  \n",
        "두번째, **엔트로피**  \n",
        "세번째, **분류 오차** 입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL-L8OArf4wd",
        "colab_type": "text"
      },
      "source": [
        "우선 **엔트로피**부터 천천히 살펴보겠습니다.  \n",
        "여기 이 부분은 특정 노드 t에서 클래스 i가 속한 데이터비율입니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84609697-f3926e00-aef2-11ea-8460-bd0d641866fb.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]12\" alt=\"RubberDuck\"></img><br/>\n",
        "그리고 이 **엔트로피의 특징**은 <u>한 노드의 모든 데이터가 같은 클래스라면 엔트로피는 0이되며  \n",
        "반대로 클래스 분포가 균등하다면 엔트로피는 최대(1)가 되죠.</u>  \n",
        "예를 들어 이진 클래스인 경우 특정 노드 t에서 클래스 i가 1일 때  \n",
        "1에 속한 비율이 완전한 1, 또는 0이라면 엔트로피 값은 0이 됩니다.  \n",
        "모든 데이터가 같은 클래스로 분류되기 때문이죠.  \n",
        "\n",
        "그럼 반대로 특정 노드 t에서 클래스 i가 1또는 0이고, 속한 비율이 각각 0.5로  \n",
        "균등하게 분포되어 있다면 엔트로피 값은 1이 됩니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84609976-eaee6780-aef3-11ea-8eeb-2cb9df8b3308.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]13\" alt=\"RubberDuck\"></img><br/>\n",
        "모든 데이터가 균등한 클래스로 분류되어 있기 때문이죠.  \n",
        "\n",
        "이렇게 엔트로피는 트리의 상호 의존 정보를  최대화하는 것으로 이해할 수가 있습니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84609848-84694980-aef3-11ea-97d5-f3b56a359526.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]14\" alt=\"RubberDuck\"></img><br/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpDVkPf8nmY1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "다음 **지니 불순도**는  \n",
        "엔트로피와 반대 개념이라 생각하시면 편합니다.  \n",
        "그 이유는  \n",
        "<u>잘못 분류될 확률을 최소화 하기 위한 기준</u>이기 때문이죠  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84610175-ab744b00-aef4-11ea-8cf0-a7d7f3d863fe.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]15\" alt=\"RubberDuck\"></img><br/>\n",
        "쉽게 말해 이 지니 불순도 값은 엔트로피 처럼 클래스 분포가 균등할 때 최대값이 되는것이 아닌 클래스가 완벽하게 섞여 있을때 최대가 됩니다.\n",
        "\n",
        "예를 들어 이진 클래스 환경에서 클래스가 완벽하게 섞여있을 때 최대값은 이렇게 계산되죠.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84610333-305f6480-aef5-11ea-918d-e8dbdfa8051b.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]16\" alt=\"RubberDuck\"></img><br/>\n",
        "실제로 지니 불순도와 엔트로피 모두 비슷한 결과를 나타냅니다.  \n",
        "그래서 지니 불순도와 엔트로피 결과를 바꿔가며 트리 평가를 진행하기보다는  \n",
        "가지치기 수준을 바꿔가며 튜닝하는 것이 권장되죠.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9a3i5bpzuj",
        "colab_type": "text"
      },
      "source": [
        "마지막 불순도 지표는 **분류 오차**입니다.  \n",
        "이 분류 오차 또한 <u>두 클래스가 같은 비율일 때  \n",
        "최대값 0.5를 출력</u>하죠.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84611064-a82e8e80-aef7-11ea-9791-6395945dca39.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]17\" alt=\"RubberDuck\"></img><br/>\n",
        "수식 또한 간단합니다.  \n",
        "하지만 이 지표는 권장되지가 않아요.  \n",
        "노드의 클래스 확률 변화에 쫌 둔감하기 때문입니다.  \n",
        "그러 실제로 두개의 분할 시나리오를 통해 세가지 지표들을 살펴 볼까요?  \n",
        "\n",
        "우선 부모노드 데이터셋 Dp로 시작합니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84611570-38210800-aef9-11ea-9d95-713625af5021.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]18\" alt=\"RubberDuck\"></img><br/>\n",
        "이 데이터 셋은 클래스 1이 40개, 클래스2가 40개로 이뤄져 있죠.  \n",
        "이를 두 개의 자식 노드, 데이터셋 D left와 D right로 나눕니다.  \n",
        "그리고 클래스 확률 변화에 조금 둔감한 분류 오차를기준으로 사용했을 때 정보 이득을 구해보면  \n",
        "우서 부모노드에 대한 불류 오차값은 1 - 0.5 이니 0.5  \n",
        "다음으로 시나리오A의 왼쪽 자식 노드에 대한 불류 오차값은 1 - 3/4이니 0.25  \n",
        "오른쪽 자식노드 또 한 0.25입니다.  \n",
        "그럼 이걸 바탕으로 정보 이득을 구해 보면  \n",
        "<u>부모 노드의 분류 오차값 마이너스  \n",
        "부모 노드의 샘플 개수분의  \n",
        "자식노드 샘플개수 곱하기  \n",
        "왼쪽 자식노드의 분류 오차값 마이너스  \n",
        "똑같이 오른쪽 자식노드의 분류 오차값을 빼주면  \n",
        "A시나리오의 최종 IG값은 0.25가 나옵니다.</u>  \n",
        "\n",
        "이번에 B시나리오를 살펴보죠.  \n",
        "똑같은 방식으로 계산 결과  \n",
        "분명 B시나리오의 데이터 분포 비율이 다름에도 불구하고  \n",
        "A와 같은 값이 출력됬죠.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84611753-b2ea2300-aef9-11ea-8bc0-18e10f833d5b.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]19\" alt=\"RubberDuck\"></img><br/>\n",
        "확실히 조금 둔감하네요.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFFd35q726ht",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "자 그럼 지니 불순도를 지표로 계산해 볼까요?  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84612143-a31f0e80-aefa-11ea-9a38-4371c2ed3e45.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]20\" alt=\"RubberDuck\"></img><br/>\n",
        "우선 A시나리오의 경우  \n",
        "부모 노드의 지니 불순도 값은  \n",
        "1마이너스 0.5제곱 플러스 0.5제곱  \n",
        "여기서 이걸(0.5제곱을) 두번 반복한 이유는  \n",
        "앞에 1과 2의 클래스에 대한 시그마가 있기 때문이에요.  \n",
        "\n",
        "다음 외쪽 자식 노드의 지니 불순도 값은  \n",
        "1마이너스 4분의 3제곱 플러스 4분의 1제곱  \n",
        "계산 결과는 0.375\n",
        "오른쪽 자식 노드의 지니 불순도 값은  \n",
        "1마이너스 4분의 1제곱 플러스 4분의 3제곱  \n",
        "계산 결과는 0.375  \n",
        "최종 정보 이득(IG) 계산 결과는 앞의 방식처럼 계산  \n",
        "즉 A시나리오의 지표는 0.125\n",
        "\n",
        "자 그럼 B시나리오 또 한 같은 방식으로 진행을 해보면  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84612252-05780f00-aefb-11ea-9bae-241661814657.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]21\" alt=\"RubberDuck\"></img><br/>\n",
        "0.16이란 값을 얻게 됩니다.  \n",
        "\n",
        "이러한 결과를 통해 지니 불순도로 기준하여  계산하면  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84612396-7f0ffd00-aefb-11ea-9ca4-02c46b6386a3.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]22\" alt=\"RubberDuck\"></img><br/>\n",
        "A시나리오 보다 B시나리오가 더 순수하다는 것을 알 수 있습니다.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd3lyYEO2_bK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "비슷하게 엔트로피 기준도 계산을 진행해보면, A시나리오의 부모 노드 엔트로피 값은 1,  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84612602-16755000-aefc-11ea-97df-1fa745614398.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]23\" alt=\"RubberDuck\"></img><br/>\n",
        "왼쪽 자식 노드의 엔트로피 값은 0.81, 오른쪽 자식 노드의 엔트로피 값도 0.81  \n",
        "A시나리오의 최종 정보이득 값은 0.19,  \n",
        "같은 방식으로 B시나리오도 계산해보면  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84612850-ca76db00-aefc-11ea-9b32-590a63c925b4.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]24\" alt=\"RubberDuck\"></img><br/>\n",
        "IG(정보이득)값은  0.31이란 값을 얻게 됩니다.  \n",
        "\n",
        "엔트로피 또한 지니 불순도와 마찬가지로 B시나리오를 더 선호한다는 것을 알 수 있죠.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84612920-fb571000-aefc-11ea-9ab2-d51413d703a4.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]25\" alt=\"RubberDuck\"></img><br/>\n",
        "\n",
        "또한 이러한 세가지의 불순도를 시각적으로 비교해보면 지니 불순도가  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84613033-3d805180-aefd-11ea-9ec0-69f4a08a7cca.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]26\" alt=\"RubberDuck\"></img><br/>\n",
        "엔트로피와 분류 오차의 중간 정도에 위치한다는 것을 확인할 수 있습니다.  \n",
        "\n",
        "그리고 이렇게 구한 계수들을 바탕으로 분할된 노드에서 다시 특정 분류 기준에 의해  \n",
        "다시 자식 노드를 생성하고 이를 바탕으로 또다시 불순도를 구하며 가지를 뻗어 나갑니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84613312-fa72ae00-aefd-11ea-95b3-e2d83f96ef64.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]27\" alt=\"RubberDuck\"></img><br/>\n",
        "그리고 최종적으로 불순도가 0에 수렴할 때까지  \n",
        "즉 하나의 클래스만을 가진 노드가 될 때까지 이를 반복해서 진행합니다.  \n",
        "그래서 무한으로 반복하다 보면 앞서 이야기한 것처럼 과적합을 불러일으키기 때문에  \n",
        "가지가 뻗어 내려가는 수준을 지정해 줘야 한다는 거죠.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We58avFn4C1T",
        "colab_type": "text"
      },
      "source": [
        "# k-근접이웃(K-Nearest Neighver)  \n",
        "**k-근접이웃(K-Nearest Neighver) KNN알고리즘**은  \n",
        "우리가 지금까지 봐왔던 개념과는 근본적으로 다릅니다.  \n",
        "우리가 지금까지 봐왔던 모델들의 특징은  \n",
        "올바른 매개변수르 찾기 위한 학습 과정을 진행하였습니다.  \n",
        "하지만 이 알고리즘은  \n",
        "훈련과정을 진행하지 않는 머신러닝 모델이기 때문이죠.  \n",
        "\n",
        "자 학습이란 개념이 적용된 알고리즘들은, 학습에 필요한 데이터를  충분히 정제 후,  \n",
        "모델 학습과정을 거치고, 최종적으로 하이퍼 파라미터 수정 등  \n",
        "일련의 과정을 모두 마쳤다면 더 이상 거대한 용량의 학습 데이터는 필요 없습니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84613750-f98e4c00-aefe-11ea-8967-754326402a49.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]28\" alt=\"RubberDuck\"></img><br/>\n",
        "하지만 KNN알고리즘은 학습이란 개념이 없으니, 매번 알고리즘을 실행할 때마다  \n",
        "모든 학습 데이터를 통해 분류를 진행합니다.  \n",
        "즉, 매번 학습 데이터가 필요하단 단점이 있죠.  \n",
        "\n",
        "또 만약 고차원의 데이터로 실험을 진행한다면,  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84613818-322e2580-aeff-11ea-89ca-41fd873eaaf3.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]29\" alt=\"RubberDuck\"></img><br/>\n",
        "계산 복잡도 또한 훈련 데이터의 개수에 비례하여 증가하는 경우도 발생합니다.  \n",
        "\n",
        "그럼에도 KNN은 데이터 정제만 잘해준다면 학습과정이 없으니,  \n",
        "빠르게 결과를 살펴볼 수 있다는 장점이 존재합니다.  \n",
        "그럼 이 기묘한 알고리즘을 쫌 더 자세하게 살펴볼까요?  \n",
        "\n",
        "KNN은 숫자 K와 거리 측정 기준을 선택합니다.  \n",
        "이때 거리 측정 기준은 일반적으로 **유클리디안 거리 측정 방식**을 사용합니다.  \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84614060-ec259180-aeff-11ea-8bbb-d46c1789afd1.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]30\" alt=\"RubberDuck\"></img><br/>\n",
        "그리고 분류하려는 미지의 데이터에서 우리가 설정한 K개의 최근접 이웃을 찾죠.  \n",
        "마지막으로 다수결 투표를 진행, 투표 결과에 따라 미지의 데이터 클래스 레이블을 할당합니다.  \n",
        "간단하죠.  \n",
        "\n",
        "이 <u>알고리즘의 핵심은 과적합과 과소적합 사이에서 올바른 균형을 잡기 위한 K값 설정</u>이 그 무엇보다 중요합니다.   \n",
        "<img src=\"https://user-images.githubusercontent.com/54702627/84614821-39a2fe00-af02-11ea-8cf6-1e6f8cfd588c.png\" width=\"450px\" height=\"300px\" title=\"머신러닝_분류_문제[2]31\" alt=\"RubberDuck\"></img><br/>\n",
        "또한 <u>**차원의 저주**라는  \n",
        "훈련 데이터셋이 차원이 늘어남에 따라  \n",
        "특성 공간도 점점 희소해지는 현상</u>을 피하기 위해  \n",
        "올바른 변수의 선택, 차원 축소 기법 등을 사용해 주시면 됩니다.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgGQwUag-L3l",
        "colab_type": "text"
      },
      "source": [
        "마지막으로 머신러닝이나 딥러닝, 강화학습 등  \n",
        "인공지능을 실현하는 기법들에게 있어  \n",
        "가장 중요한건  \n",
        "적절한 학습 알고리즘 선택도 있지만  \n",
        "더 중요하게 이야기 되는 건  \n",
        "훈련 데이터셋을 이루는 데이터들입니다.  \n",
        "그 어떠한 알고리즘도 정보가 풍부하고 판단에 도움이 되는 특성없이는  \n",
        "좋은 예측을 이뤄낼 수 없기 때문이죠.  \n",
        "만약 내가 머신러닝 모델에 대해 조금은 감이 잡히신다면  \n",
        "그 다음 단계는 데이터 전처리, 특성선택, 차원축소등과 같은 데이터에 대한 구분이지 않을까합니다.  \n",
        "자 오늘의 수업은 여기서 마무리..\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZtODsXBNSbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}